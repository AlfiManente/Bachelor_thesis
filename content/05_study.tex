\chapter{Analysis and Results}
\label{chapter5}

\section{Analysis Strategy}

Throughout this analysis, steps are taken to determine the signal strength $\mu_{\rm{s-chan.}}=\sfrac{\sigma_{\rm{s-chan.}}^{\rm{measured}}}{\sigma_{\rm{s-chan.}}^{\rm{theory}}}$ of the single top quark s--channel process. 
This is done via a binned likelihood fit, where a \textit{Deep Neural Network} (DNN) output is used as discriminant value, to descern signal events from background events.
Only one signal region, passing the event selection in \autoref{tab:eventsel}, is defined in this thesis.
As systematic uncertainties are the limiting factors in the search for the single top quark s--channel process, the systematics with the biggest impact are further inspected and discussed. 


\section{DNN Model}
\label{subsec:dnn}

The single top quark s--channel process is dominated by large backgrounds.
Extracting signal events from this large background is rather difficult. 
To achieve an optimal separation between signal and background, a multivariate approach that uses as much kinematic information as possible is required.
For this reason, a DNN classification will be used as the discriminant variable in the binned likelihood fit.
The DNN used in this analysis was designed by Niklas Düser as part of his Master's Thesis at the \textit{Technische Universität Dortmund} \cite{niklas_master}. 
It makes use of several high--level kinematic variables to distinguish signal events from background events. 
The network architecture consists of an input layer with 128 nodes, followed by four hidden layers with 256, 64, 32 and 16 nodes, respectively.
The model was trained using the \textsc{Keras} API within the \textsc{TensorFlow} framework\,\cite{keras, tensorflow}, employing the binary cross--entropy loss function and the Adam optimizer\,\cite{adam}.
For the training and validation datasets, the single top quark s-channel events were used as signal, while the $\ttbar$ process, the single top quark t-channel and associated $tW$ production processes, as well as the $W$+jets and $Z$+jets processes constitute the background. 
The training samples correspond to an integrated luminosity of $\SI{28}{fb^{-1}}$.
For every single particle that gets reconstructed, the kinematic variables $\pT, \eta, \varphi$ and the invariant mass $m$ get included as features for the DNN model.
For particle pairs their pseudorapidity difference $\Delta \eta$ and the difference in the azimuthal angle $\Delta \varphi$ is incorporated as a feature.
From the detector measurements of the final state particles, every other particle can be retraced up to the virtual $W$-boson. 
First, the final state lepton and corresponding neutrino are reproduced. 
%The neutrino cannot be measured directly via the detector but is inferred via studying the missing transverse momentum $\etmiss$ of the event and further implying the longitudinal impulse of the neutrino, 
From the condition that the leptons and the neutrinos momentum squared must equal the invariant mass of the decaying $W_{\rm{Decay}}$-boson the neutrino four-momentum is reconstructed.
With the lepton and neutrino reconstructed, the top quark mass can be calculated.
With information about the leading $b$-tagged jet and the $W_{\rm{Decay}}$-boson, the top quark can be reconstructed.
The top quark four-momentum and the second b-tagged jet are then used to reconstruct the virtual $W_{\rm{Prod.}}$-boson.
The transverse mass of the $W_{\rm{Decay}}$-boson $\mtw$ and the missing transverse momentum $\etmiss$ of the event are included as feature.
The transverse mass of the top quark, defined as $m_{\rm{T}}^{\rm{top}} = \sqrt{E_{\rm{T,sum.}}^2 - p_{\rm{T,sum.}}^2}$, with the sums of the transverse energies and transverse momenta of the top quarks decay particles, is also used. 
The scalar sum of the transverse energies of all final-state paricles is called $H_{\rm{T}}$, whereas $H_{\rm{T,had.}}$ and $H_{\rm{T,lep}}$ sum only over the transverse energies of the final state hadrons or leptons respectively.
Another set of event shape variables are inferred through the momentum tensor, that encodes the high-levels momentum distributions of the reconstructed objects. Its elements are derived by the formular

\begin{equation*}
    M_{ij}=\frac{\sum^N_{k=1} p_{k,i}p_{k,j}}{\sum^N_{k=1} p_k^2}, ~ i,j \in x,y,z
\end{equation*}

by summing over all final-state particles, where $p_{k,i}$ denotes the $i$-th component of the $k$-th final state particle. 
Through the sorted eigenvalues of the momentum tensor $\lambda_0 > \lambda_1 > \lambda_2$ further event variables are constructed:

\begin{align*}
    &\text{Aplanarity}:  & \mathcal{A} &= \frac{3 \lambda_2}{2}, \\
    &\text{Planarity}:   & \mathcal{P} &= \frac{3(\lambda_2 + \lambda_1)}{2}, \\
    &\text{Sphericity}:   & \mathcal{S} &= \lambda_1 - \lambda_2. \\
\end{align*}

The DNN responds particularly sensitive to momentum variables.
Especially, the transverse momenta of the two $b$-tagged jets and the top quark have the biggest impact on the DNN output.
The DNN is applied to all signal and background events in the SR.
The corresponding distributions are shown in \autoref{fig:dnn_output}.
\autoref{subfig:separation} shows signal and background normalized to the same integral, to show the achieved separation of the classifier.
The combined DNN output histograms of each respective process is shown in \autoref{subfig:histos}.



%Möchte ich hier nochmal auf die Tabelle in Kap 4 Referenzieren?
%The event yields given out from the DNN are shown in \autoref{tab:yields}.

\begin{figure}
    \centering
    \begin{subfigure}{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{imgs/seperation.png}
        \caption{The separation plot shows the output score of the DNN on the $x$-axis for the $s$-channel signal histogram and the sum of the background histograms. Both histograms are normalised. A separation of $30.1 \%$ is achieved, displayed by the observably separated peaks with yet significant overlap of both distributions.}
        \label{subfig:separation}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{imgs/SR-Schannel.png}
        \caption{The combined DNN output for every process of interest in this analysis. Histograms are stacked, where the signal events are displayed in \textcolor{red}{red} on the top of the stack.}
        \label{subfig:histos}
    \end{subfigure}
    \caption{The DNNs output is shown with a separation plot and the combined DNN output for the different processes.}
    \label{fig:dnn_output}
\end{figure}


\section{Statistical Method}

With the neural network output $x$ as the discriminant, the expected number of events in the $i$-th bin $\lambda_i (\mu, \theta) = \mu \cdot s_i (\theta) + b_i (\theta)$ is used to incorporate the signal strength. 
Here $s_i(\theta)$ and $b_i(\theta)$ signify the expected signal and background contributions respectively, which are obtained by processing the simulated signal and background events through the trained DNN model and evaluating the corresponding output score $x$.
The parameter $\mu$ represents the signal strength and scales the overall signal contribution uniformly across all bins, while the nuisance parameters (NPs) $\theta$ encode the effect of systematic uncertainties on both the normalization and the shape of the signal and background distributions.
To determine the cross-section, a \textit{binned profile likelihood fit} is performed with the \textsc{HistFactory} tool\,\cite{histfactory}.
This framework is used to extract the signal strength parameter $\mu$ together with the NPs describing systematic uncertainties by maximizing the likelihood function.
This determines the parameter values that best describe the data assuming the presence of the single top quark s-channel signal.
The likelihood function states the probability by which an outcome happens with respect to a set of given model parameters. 
Since this analysis involves a large event sample, the data are represented in histograms, where events are grouped into bins rather than treated individually.
The binning of data also introduces Poisson probabilities into the likelihood as can be seen in the following equation:

\begin{equation*}
    \mathcal{L}(\mu, \theta) = \prod_{i=1}^{N_{\rm{bins}}} \rm{Pois}(n_i|\lambda_i(\mu, \theta)) \cdot \prod_{j=1}^{N_{\rm{NP}}}\pi_j (\theta_j) ~.
\end{equation*}

The binned likelihood function multiplies the Poisson probabilities $\rm{Pois} (n|\lambda)$ in each bin, which state the probability of observing $n$ events under the expectation $\lambda$

\begin{equation*}
    \rm{Pois} (n|\lambda) = \frac{\lambda^n e^{-\lambda}}{n!},
\end{equation*}

multiplied with the product of all constraint terms $\pi_j (\theta_j)$ for each NP $j$.
A NP of $\theta_j = 0$ resembles the nominal prediction made by the simulation, while $\theta_j = \pm 1$ represents a variation of one standard deviation $\pm \sigma$. 
For most systematic uncertainties, the constraint terms are modelled as Gaussian distributions centered at the nominal value $\theta_j^0$ with a width corresponding to the estimated uncertainty $\sigma_{\theta_j^0}$.
The one standard deviation variations are provided in the form of up and down shifted histograms.
Statistical uncertainties arising from the limited number of simulated events are included as dedicated  NPs $\gamma_i$ for each respective bin $i$, which are modelled as Poisson-constrained parameters with a nominal value of 1.
By maximizing the likelihood function via variaton of the parameters $\mu$ and $\theta_j$, their final values are determined by $\displaystyle \hat{\mu}, \hat{\theta} = \operatorname*{argmax}_{\mu, \theta} \mathcal{L}(\mu, \theta)$.
In practice, the negative logarithm of the likelihood function $-\ln \mathcal{L}$ is minimized, as the maximum is unaffected by taking the logarithm and the multiplications are transformed into sums.
Summing over the logarithms and minimizing is computationally more robust. 
The negative log-likelihood (NLL) function is minimized with \textsc{Minuit}\,\cite{minuit}.
The signal strength $\mu$ and all NPs can vary while fitting.
$\mu$ is free-floating, while the NPs are penalized based on their respective uncertainties. 
If after the fit the uncertainty of a NP is smaller then the provided uncertainty $\sigma_{\theta_j^0}$, the fit achieved a constraint on the respective systematic uncertainty. 

To assess the expected sensitivity of the analysis and study the impact of systematic uncertainties in the absence of statistical fluctuations, an \textit{Asimov fit} is performed.
The \textit{Asimov dataset} is constructed by replacing the observed event counts in each bin with their expected values under the nominal SM predictions.
The Asimov fit provides the expected best-fit values and uncertainties of the signal strength and nuisance parameters, assuming perfect agreement between data and the model.

%It is commonly used to evaluate the expected precision of the measurement, to study the constraining power of the data on systematic uncertainties, and to disentangle statistical and systematic contributions to the total uncertainty.
%Das wird mir ein bisschen zu viel

\section{Systematic Uncertainties}

The systematic uncertainties are categorized into modelling uncertainties of the single top quark s-channel signal process, background modelling uncertainties with a particular focus on the $\ttbar$ process, and detector modelling uncertainties.

Modelling uncertainties arise from different theoretical descriptions of the hard-scattering process and its subsequent evolution, including variations in ME calculations, PS modelling, hadronization, and the choice of generator-specific parameters.
For the single top quark s-channel signal process, additional MC samples were produced by varying the $\pT^{\rm hard}$ parameter to 1, compared to the nominal value of 0. 
The $\pT^{\rm hard}$ variable determines how the event hardness calculated by \textsc{Powheg} is passed to \textsc{Pythia} to regulate the PS modelling. 
Nominally, the hardness scale variable \textit{SCALUP} given by \textsc{Powheg} is used for the event hardness. 
When setting $\pT^{\rm hard}=1$, the event hardness is instead defined by the transverse momentum of the hardest \textsc{Powheg} emission\,\cite{pthard}. 
This variation probes uncertainties related to the matching between the NLO matrix element and the PS.
In addition, samples interfacing \textsc{Powheg} with \textsc{Herwig} were generated to assess uncertainties originating from different parton shower and hadronization models.
Similar modelling variations were applied to the $\ttbar$ background process.
Further $\ttbar$ samples were produced with $\pT^{\rm hard}=1$, and with the $h_{\rm{damp}}$ parameter increased from $1.5 \cdot m_{\rm top}$ to $3 \cdot m_{\rm top}$, allowing the study of uncertainties related to the modelling of high-$p_T$ radiation in the hardest emissions.

In addition to ME and PS modelling uncertainties, background processes are subject to uncertainties in their theoretical cross-section predictions, which affect their normalization. 
A cross-section uncertainty of $5.2\%$\,\cite{tt_xsec} is assigned to the $\ttbar$ background and $3.7\%$\,\cite{t_xsec} to the single top quark production modes. 
For the $W$+jets and $Z$+jets background processes, a conservative uncertainty of $50\%$ is assumed.

Detector modelling uncertainties include both one-sided and two-sided systematic variations. 
Two-sided systematics are provided with independent up and down variations, while one-sided systematics are symmetrised with respect to the nominal distribution. 
The latter include uncertainties on the missing transverse momentum $\etmiss$, parametrising the resolution of the Track Soft Term (TST) in directions parallel and perpendicular to the hard-scatter axis.
The integrated luminosity uncertainty is taken to be $0.83\%$~\cite{lumi_unc}.
Jet-related uncertainties include jet energy resolution (JER), jet vertex tagger (JVT), and jet energy scale (JES) uncertainties. 
The JER uncertainty is represented by 15 NPs, while two efficiency-related nuisance parameters are used for JVT. 
The JES uncertainty accounts for effects related to jet flavor composition, flavor response, $b$-jet energy scale, pile-up, punch-through, and jet $\eta$ intercalibration, as well as various pre-recommendations, and is encoded using 32 nuisance parameters.
Flavor tagging uncertainties are modelled using 55 nuisance parameters for $b$-tagging, 33 for $c$-tagging, and 42 for light-flavor jet tagging. 
In addition, four nuisance parameters per flavor are included to describe uncertainties arising from the extrapolation of the jet calibration to the high transverse momentum regime.
Uncertainties related to the modelling of electrons and muons are also considered.
For electrons, six nuisance parameters are included, covering trigger efficiencies as well as energy scale and resolution effects for electrons and photons. 
For muons, 16 nuisance parameters are used to describe momentum scale and resolution uncertainties, as well as trigger-related effects. 
The uncertainty associated with pile-up reweighting is represented by a single nuisance parameter.

Additional theoretical uncertainties affecting both the single top quark s-channel signal and the $\ttbar$ background arise from variations of the renormalization and factorization scales, as well as from initial- and final-state radiation modelling.

In order to be less dependent on statistical fluctuations, the systematics distributions are smoothed. 
For uncertainties containing an up and down variation, two-sided symmetrization is applied. 
The up and down variation for each respective bin $i$ consists therefore of the mean of both, given by $\pm \frac{n_i^{\rm{up}} - n_i^{\rm{down}}}{2}$.
Uncertainties with only an up or down variation undergo one-sided symmetrization, in which the the existing variation is mirrored for the missing counterpart.  

\section{Results}

After fitting the NLL onto the Asimov dataset, the expected signal strength is found to be $\mu_{\rm{s-chan.}} = 1^{+0.25}_{-0.20}$.
From the fit the NPs influences on the signal strength are now accessible. 
The ranking plot sorts the NPs, with the most influential NP shown on the top of the plot, based on their impact on the signal strength. 
Their respective impacts are calculated using the \textit{covariance matrix method} \cite{covariance_matrix_method}.
Here the impact $I=\sigma_\text{total}^{\mu} C_{\mu,\rm{NP}} \sigma^{\rm{NP}}$ is determined with the correlation $C_{\mu,NP}$ between the signal strength and the respective NP, the total uncertainty $\sigma_\text{total}^{\mu}$ of the signal strength and the uncertainty $\sigma^{\rm{NP}}$ of the NP. 
The ranking therefore reflects the sensitivity of the analysis to variations of individual nuisance parameters and provides insight into the dominant sources of systematic uncertainty.
The ranking plot for this analysis is displayed in \autoref{fig:ranking}.

 
%The pre-fit impact of a NP is determined by calculating the shift in the signal strength between the nominal fit and a fit where the respective NP is fixed to the value $\hat{\theta} \pm \Delta \theta$. 
%Here $\Delta \theta = 1$, which resembles the pre-fit uncertainty of the NP parameter of one standard deviation $\sigma$ as used in the constraint term.
%For the post-fit impact a nominal fit and a fit where the NP is fixed with the value $\hat{\theta} \pm \Delta \hat{\theta}$ is compared.
%$\Delta \hat{\theta}$ describes the uncertainty of the NP after the fit, with $\hat{\theta}$ being the value for the respective NP maximizing the likelihood function. 


\begin{figure}
    \centering
    \includegraphics[width=0.7\textwidth]{imgs/Ranking_SigXsecOverSM_Breakdown.png}
    \caption{The ranking plot sorts the NPs from top to bottom regarding their impact on the signal strength.}
    \label{fig:ranking}
\end{figure}

The ranking plot reveals that the dominant uncertainty originates from the PS and hadronization modelling of the single top quark s-channel signal process. 
This is expected, as the hadronic signature of the signal consists only of two $b$-tagged jets, whose relative kinematics are strongly influenced by the modelling of hard emissions and subsequent showering.
The leading and subleading jet transverse momenta are the most impactful input features of the DNN, as seen in \autoref{subsec:dnn}. 
This explains the strong sensitivity to PS and hadronization uncertainties, as these directly affect the jet kinematics exploited by the classifier.
On detector level, jet energy resolution uncertainties, in particular the noise pre-recommendation uncertainty and the effective NP~1 uncertainty, have a sizable impact. 
These uncertainties affect the reconstructed jet momenta and therefore propagate directly to high-level kinematic variables used by the DNN.
Uncertainties related to the modelling of the $\ttbar$ background, including the theoretical prior on the $\ttbar$ cross-section and the renormalization scale uncertainty $\mu_{\rm R}$, also show a significant impact. 
As $\ttbar$ constitutes the dominant background process and the signal-to-background ratio of the single top $s$-channel is small, the analysis is particularly sensitive to variations in the $\ttbar$ kinematic description.
In particular, variations of the renormalization scale affect the amount of QCD radiation in the $\ttbar$ process, leading to altered jet multiplicities and kinematic distributions, which in turn influence the DNN output.
In addition to parton shower and hadronization uncertainties, the ME matching uncertainty exhibits a strong impact on the extracted signal strength. The ME matching procedure governs the transition between hard emissions described by the fixed-order matrix element and soft or collinear radiation modelled by the PS. 
For the single top quark s-channel process, which is characterised by a very simple hadronic final state consisting of only two $b$-tagged jets, the modelling of additional radiation plays a particularly important role. Variations in the ME matching scheme affect the jet multiplicity as well as the transverse momentum and angular correlations of the $b$-jets.
Since the DNN relies strongly on jet-related high-level kinematic variables, these modelling differences propagate directly to the classifier output, leading to a sizeable shape effect. Moreover, the ME matching uncertainty cannot be efficiently constrained by the fit, as it does not primarily affect the overall normalization but rather the kinematic structure of the signal events.
Pile-up refers to additional $pp$ interactions occurring in the same or neighboring bunch crossings as the hard-scatter event. 
These interactions introduce extra tracks and energy deposits in the detector, which can bias the reconstruction of jets, missing transverse momentum and other event-level observables.
Uncertainties related to pile-up reweighting therefore affect jet multiplicities, jet energies and several high-level kinematic variables, and consequently propagate to the DNN classification.
Final State Radiation (FSR) uncertainties of the $\ttbar$ background process similarly influence hadronic signatures from the major background source.
The remaining JER and JES uncertainties also effect the jet reconstruction on the detector level.
Overall, the dominant uncertainties are those affecting the kinematic properties of jets and the modelling of QCD radiation, highlighting the strong interplay between the DNN-based event classification and the theoretical and detector-level description of jet-related observables.
Ratio plots of the uncertainties discussed in detail are shown in \autoref{fig:ratioplots}.
These plots show the relative variation of a given observable under the up- and down-variations of a NP with respect to the nominal prediction.

%The upper pad of each plot typically displays the nominal distribution together with the up- and down-variations, while the lower pad shows the ratio. A deviation from unity indicates that the corresponding uncertainty has an effect on the predicted distribution.
%The plots allow a visual assessment of how each uncertainty modifies the kinematic features used by the DNN classifier, providing an intuitive complement to the quantitative ranking of nuisance parameters.

\noindent

\begin{figure}
    \centering
    % Ratio Plot: s-channel PS/hadr
    \begin{subfigure}{0.48\textwidth}
        \centering
        \includegraphics[width=0.95\textwidth]{imgs/syst/ps_sig.png}
        \caption{PS and hadronization modelling (signal). \\}
        \label{subfig:pshadwignal}
    \end{subfigure}
    \hfill
    % Ratio Plot: JERUnc_Noise_PreRec
    \begin{subfigure}{0.48\textwidth}
        \centering
        \includegraphics[width=0.95\textwidth]{imgs/syst/jer_noise.png}
        \caption{The JER noise pre-recommendation uncertainty (signal).}
        \label{subfig:jernoiseprerec}
    \end{subfigure}
    % Ratio Plot: JER_EffectiveNP_1
    \begin{subfigure}{0.48\textwidth}
        \centering
        \includegraphics[width=0.95\textwidth]{imgs/syst/jer_effective.png}
        \caption{The JER effective NP~1 uncertainty (signal).}
        \label{subfig:jereffnp1}
    \end{subfigure}
    \hfill
    % Ratio Plot: ttbar mu_R
    \begin{subfigure}{0.48\textwidth}
        \centering
        \includegraphics[width=0.95\textwidth]{imgs/syst/mur_ttbar.png}
        \caption{Uncertainty for the renormalization scale $\mu_{\rm{R}}$ for the $\ttbar$ background process.}
        \label{subfig:ttbarmur}
    \end{subfigure}
    % Ratio Plot: s-channel ME matching
    \begin{subfigure}{0.48\textwidth}
        \centering
        \includegraphics[width=0.95\textwidth]{imgs/syst/me_match_sig.png}
        \caption{ME matching uncertainty (signal).}
        \label{subfig:mesignal}
    \end{subfigure}
    \hfill
    % Ratio Plot: ttbar cros section
    \begin{subfigure}{0.48\textwidth}
        \centering
        \includegraphics[width=0.95\textwidth]{imgs/syst/pileup.png}
        \caption{Pile-up reweighting uncertainty (signal).}
        \label{subfig:pileup}
    \end{subfigure}
    \caption{Ratio plots for the six uncertainties with the largest variations. The upper pad of each plot displays the nominal distribution together with the up- and down-variations, while the lower pad shows the ratio.}
    \label{fig:ratioplots}
\end{figure}

%\newpage

The overall impact of systematic uncertainties is reduced in this analysis compared to the previous measurement.  
Especially of note are the improvements in the $\ttbar$ shape modelling uncertainties.
In particular the effects of the PS uncertainties are diminished.
This improvement is illustrated in \autoref{tab:cat_impact_sigxsecoversm}, which shows the percentage impact of the systematic uncertainties grouped by categories. 
For the comparison of the impact of systematic uncertainties between analyses, the category-wise impacts were determined.
All nuisance parameters within a given category were fixed and then fitted, and the resulting change in the signal strength was compared to the nominal full fit.
The reduction of the uncertainties can be attributed to the DNN's ability to exploit a large set of high-level kinematic features and to capture non-linear correlations between them. In contrast, the MEM is limited to a smaller set of observables and simplified correlations, which makes it more sensitive to individual variations in the input distributions. 
In addition, several systematic uncertainties have been refined since the previous measurement. 
The ME matching uncertainty for the respective MC samples has been updated and the JER uncertainty now includes a larger set of effective nuisance parameters.
These uncertainties directly affect the high-level kinematic variables used as input features in the DNN, such as the transverse momenta of the leading and subleading jets and the event-level correlations between them. 
By providing a more detailed and accurate modelling of these effects, the improved uncertainties reduce unrealistic variations in the input features, which in turn leads to a smaller propagated impact on the DNN classification and the measured signal strength. 



%The impact of the overall uncertainties are diminished by the DNN model in comparison the the MEM method used in the previous measurement. 
%This is displayed in \autoref{tab:cat_impagt_sigxsecoversm}, where the procentual impact of the systematics grouped by categories are displayed.
%These were determined similarly to the single impacts on shown in the ranking plot. 
%Here the whole set of NPs corresponding to a category are fixed while fitting and then compared to full fit. 


\begin{table}
    \centering
    \caption{Category-wise impact of systematic uncertainties on the fitted signal strength, in order of their impacts on this analysis. Systematic uncertainties of this analysis are compared with the impacts in the previous measurement\,
    \cite{lastmeasure_atlas}. This analysis foregoes a more detailed subcategorization of the signal and background modelling uncertainties.}
    \label{tab:cat_impact_sigxsecoversm}
    \begin{tabular}{l c c}
        \toprule
        \makecell[l]{Systematic} &
        \makecell[c]{Previous measurement \\ $\frac{\Delta \mu}{\mu}\,[\%]$} &
        \makecell[c]{This analysis \\ $\frac{\Delta \mu}{\mu}\,[\%]$} \\
        %Systematic & Previous measurement: $\frac{\Delta \mu}{\mu} [\%]$ & Current measurement  $\frac{\Delta \mu}{\mu} [\%]$ \\
        \midrule
        s-channel modelling             & $+ 18/- 8$  & $+ 18/- 12$ \\
        Jet Energy Resolution           & $+ 18/- 12$ & $+ 11/- 9$ \\
        $\ttbar$ shape modelling        & $+ 18/ -15$ & $+ 7/- 6$ \\
        Jet Energy Scale                & $+ 18/- 13$ & $+ 5/- 4$ \\
        Missing Transverse Momentum     & $+1 /-1$    & $+ 5/- 4$ \\
        Flavor Tagging                  & $+ 12/- 10$ & $+ 4/- 4$ \\
        $\ttbar$ normalization          & $+24 /-17$  & $+ 4/- 3$ \\
        Pile-up Reweighting             & $+ 5/- 3$   & $+ 4/- 3$ \\
        $W$+jets normalization          & $+11/-8 $   & $+ 3/- 2$ \\
        Normalization of other processes& $+ 6/- 5$   & $+ 3/ -2$ \\
        Other detector sources          & $+1/-1$     & $+ 2/ -2$ \\
        MC statistics                   & $+ 13/- 11$ & $+ 1/- 1$ \\
        Luminosity                      & $+ 4/- 3$   & $+ 1/- 1$ \\
        \midrule
        Systematic uncertainties        & $+ 42/- 34$ & $+ 21/- 19$ \\
        \midrule        
        Statistical uncertainties       & $+ 8/- 8$      & $+ 12/- 6$  \\
        \midrule 
        Total                           & $+ 42/- 35$ & $+ 25/- 20$  \\
        \bottomrule
    \end{tabular}
\end{table}